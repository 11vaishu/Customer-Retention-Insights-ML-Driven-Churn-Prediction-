# -*- coding: utf-8 -*-
"""churn prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YEu78QAhz6-TsgzrJWElK5BrG_wfTMtO
"""

# Step 1: Install Kaggle CLI
!pip install -q kaggle

# Step 2: Upload your kaggle (1).json
from google.colab import files
uploaded = files.upload()  # Upload the file again if needed

# Step 3: Create .kaggle directory if it doesn't exist
import os
if not os.path.exists("/root/.kaggle"):
    os.makedirs("/root/.kaggle")

# Step 4: Rename and move to .kaggle
import shutil
shutil.move("kaggle (2).json", "/root/.kaggle/kaggle.json")

# Set correct permissions
!chmod 600 /root/.kaggle/kaggle.json

# Download the dataset
!kaggle datasets download -d blastchar/telco-customer-churn

# Unzip the dataset
!unzip telco-customer-churn.zip

# Load dataset
import pandas as pd

df = pd.read_csv("WA_Fn-UseC_-Telco-Customer-Churn.csv")
df.head()

# Basic structure
print("Shape of dataset:", df.shape)

# Column info and data types
df.info()

# Check for missing values
df.isnull().sum()

# Reload the raw dataset (adjust the filename if different)
df = pd.read_csv("WA_Fn-UseC_-Telco-Customer-Churn.csv")

# Convert TotalCharges to numeric
df["TotalCharges"] = pd.to_numeric(df["TotalCharges"], errors="coerce")

# Drop rows with NaN in TotalCharges
df = df.dropna(subset=["TotalCharges"])

# âœ… Extract target variable BEFORE encoding
y = df["Churn"].map({"No": 0, "Yes": 1})

# Drop unnecessary columns
X = df.drop(columns=["customerID", "Churn"])

# Encode categorical variables
X = pd.get_dummies(X, drop_first=True)

# Check final shapes & distributions
print("X shape:", X.shape)
print("y shape:", y.shape)
print("y distribution:\n", y.value_counts())
print("y distribution (normalized):\n", y.value_counts(normalize=True))

import seaborn as sns
import matplotlib.pyplot as plt

# Plot churn distribution
sns.countplot(x='Churn', data=df)
plt.title("Churn Count")
plt.show()

sns.countplot(x='Contract', hue='Churn', data=df)
plt.title("Churn by Contract Type")
plt.show()

sns.countplot(x='InternetService', hue='Churn', data=df)
plt.title("Churn by Internet Service Type")
plt.show()

sns.histplot(data=df, x='tenure', hue='Churn', multiple='stack', bins=30)
plt.title("Churn by Tenure")
plt.show()

# ==============================
# 2. Train/Test Split + Baseline Models
# ==============================

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, recall_score

# Split data (80% train, 20% test, stratify to preserve churn ratio)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print("Train set size:", X_train.shape)
print("Test set size:", X_test.shape)
print("Churn distribution in train set:\n", y_train.value_counts(normalize=True))
print("Churn distribution in test set:\n", y_test.value_counts(normalize=True))

# ==============================
# Logistic Regression (baseline)
# ==============================

# Scale features for Logistic Regression (important for optimization)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Logistic Regression with balanced class weights
log_model = LogisticRegression(class_weight="balanced", max_iter=1000, random_state=42)
log_model.fit(X_train_scaled, y_train)
y_pred_log = log_model.predict(X_test_scaled)

print("\nLogistic Regression Results:")
print(confusion_matrix(y_test, y_pred_log))
print(classification_report(y_test, y_pred_log))
print("Recall (churn=1):", recall_score(y_test, y_pred_log))

# ==============================
# Random Forest (baseline)
# ==============================

rf_model = RandomForestClassifier(
    class_weight="balanced", n_estimators=200, random_state=42
)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)

print("\nRandom Forest Results:")
print(confusion_matrix(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf))
print("Recall (churn=1):", recall_score(y_test, y_pred_rf))

# ==============================
# 3. Model Upgrades
# ==============================

from xgboost import XGBClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report, recall_score, precision_recall_curve
import numpy as np

# ==============================
# 3.1 XGBoost Model
# ==============================
# Handle imbalance with scale_pos_weight = (negatives / positives)
scale_pos_weight = (len(y_train) - sum(y_train)) / sum(y_train)

xgb_model = XGBClassifier(
    scale_pos_weight=scale_pos_weight,
    eval_metric="logloss",
    use_label_encoder=False,
    random_state=42
)

xgb_model.fit(X_train, y_train)
y_pred_xgb = xgb_model.predict(X_test)

print("\nXGBoost Results:")
print(classification_report(y_test, y_pred_xgb))
print("Recall (churn=1):", recall_score(y_test, y_pred_xgb))


# ==============================
# 3.2 Hyperparameter Tuning
# ==============================

# Logistic Regression tuning
log_params = {"C": [0.01, 0.1, 1, 10], "penalty": ["l2"]}
grid_log = GridSearchCV(
    LogisticRegression(class_weight="balanced", max_iter=1000, solver="lbfgs"),
    log_params, scoring="recall", cv=5
)
grid_log.fit(X_train_scaled, y_train)
print("\nBest Logistic Regression params:", grid_log.best_params_)

# Random Forest tuning
rf_params = {
    "n_estimators": [100, 200, 500],
    "max_depth": [None, 10, 20],
    "min_samples_split": [2, 5, 10]
}
grid_rf = GridSearchCV(
    RandomForestClassifier(class_weight="balanced", random_state=42),
    rf_params, scoring="recall", cv=3, n_jobs=-1
)
grid_rf.fit(X_train, y_train)
print("Best Random Forest params:", grid_rf.best_params_)


# ==============================
# 3.3 Threshold Tuning (Logistic Regression)
# ==============================

# Get probability predictions
y_proba_log = log_model.predict_proba(X_test_scaled)[:, 1]

# Precision-Recall curve
precisions, recalls, thresholds = precision_recall_curve(y_test, y_proba_log)

# Pick threshold where recall >= 85% (tune as needed)
target_recall = 0.85
best_thresh = thresholds[np.argmax(recalls >= target_recall)]

print("\nChosen threshold for recall >= 85%:", best_thresh)

# Apply new threshold
y_pred_thresh = (y_proba_log >= best_thresh).astype(int)

print("\nLogistic Regression with Tuned Threshold:")
print(classification_report(y_test, y_pred_thresh))
print("Recall (churn=1):", recall_score(y_test, y_pred_thresh))

# ==============================
# 4. Visualization & Model Comparison
# ==============================
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay

# ------------------------------
# 4.1 Confusion Matrices
# ------------------------------
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

ConfusionMatrixDisplay.from_estimator(log_model, X_test_scaled, y_test, cmap="Blues", ax=axes[0])
axes[0].set_title("Logistic Regression")

ConfusionMatrixDisplay.from_estimator(rf_model, X_test, y_test, cmap="Greens", ax=axes[1])
axes[1].set_title("Random Forest")

ConfusionMatrixDisplay.from_estimator(xgb_model, X_test, y_test, cmap="Oranges", ax=axes[2])
axes[2].set_title("XGBoost")

plt.suptitle("Confusion Matrices for All Models", fontsize=16)
plt.show()


# ------------------------------
# 4.2 ROC Curve Comparison
# ------------------------------
plt.figure(figsize=(8,6))

RocCurveDisplay.from_estimator(log_model, X_test_scaled, y_test, name="Logistic Regression")
RocCurveDisplay.from_estimator(rf_model, X_test, y_test, name="Random Forest")
RocCurveDisplay.from_estimator(xgb_model, X_test, y_test, name="XGBoost")

plt.plot([0,1],[0,1],'k--')  # baseline
plt.title("ROC Curve Comparison")
plt.show()


# ------------------------------
# 4.3 Feature Importances
# ------------------------------

# Random Forest feature importance
importances_rf = rf_model.feature_importances_
indices_rf = np.argsort(importances_rf)[-10:]  # top 10

plt.figure(figsize=(8,6))
plt.barh(range(len(indices_rf)), importances_rf[indices_rf], align="center", color="green")
plt.yticks(range(len(indices_rf)), [X.columns[i] for i in indices_rf])
plt.title("Top 10 Features Driving Churn (Random Forest)")
plt.xlabel("Feature Importance")
plt.show()

# XGBoost feature importance
importances_xgb = xgb_model.feature_importances_
indices_xgb = np.argsort(importances_xgb)[-10:]  # top 10

plt.figure(figsize=(8,6))
plt.barh(range(len(indices_xgb)), importances_xgb[indices_xgb], align="center", color="orange")
plt.yticks(range(len(indices_xgb)), [X.columns[i] for i in indices_xgb])
plt.title("Top 10 Features Driving Churn (XGBoost)")
plt.xlabel("Feature Importance")
plt.show()